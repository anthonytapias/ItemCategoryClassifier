{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saves dictionary in same format\n",
    "# np.save('my_file.npy', all_desc) \n",
    "\n",
    "# # # Loads dictionary in same format so we don't have to webscrape all the time\n",
    "read_dictionary = np.load('my_file.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "edu  = read_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['EDUCATION', 'BUSINESS', 'DATING', 'SPORTS', 'WEATHER', 'FOOD_AND_DRINK', 'HEALTH_AND_FITNESS', 'BEAUTY', 'MUSIC_AND_AUDIO', 'NEWS_AND_MAGAZINES', 'SOCIAL', 'SHOPPING', 'PRODUCTIVITY', 'PHOTOGRAPHY', 'MEDICAL', 'PARENTING', 'COMMUNICATION', 'TOOLS'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edu.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "\n",
    "from nltk.collocations import *\n",
    "from nltk import FreqDist, word_tokenize\n",
    "import string, re\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patter to capture using regex\n",
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words(\"english\")\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem words\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(description):\n",
    "    ''''''\n",
    "    tokens_raw = nltk.regexp_tokenize(description, pattern)\n",
    "    tokens = [i.lower() for i in tokens_raw]\n",
    "    tokens_stopped = [w for w in tokens if not w in stop_words]\n",
    "    stemmed = [stemmer.stem(word) for word in tokens_stopped]\n",
    "    cleaned = ' '.join(stemmed)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_cleaner(dictionary):\n",
    "    description_list = []\n",
    "    for c, d in dictionary.items():\n",
    "        for review in d:\n",
    "            cleaned = text_cleaner(review)\n",
    "            description_list.append(cleaned)\n",
    "    return description_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_list = dict_cleaner(edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tfidf.fit_transform(description_list)\n",
    "\n",
    "df = pd.DataFrame(response.toarray(), columns=tfidf.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Non-Zero Elements in Vectorized Reviews: 112.69537037037037\n",
      "Percentage of columns containing 0: 0.9914657046292791\n"
     ]
    }
   ],
   "source": [
    "non_zero_cols = response.nnz / float(response.shape[0])\n",
    "print(\"Average Number of Non-Zero Elements in Vectorized Reviews: {}\".format(non_zero_cols))\n",
    "\n",
    "percent_sparse = 1 - (non_zero_cols / float(response.shape[1]))\n",
    "print('Percentage of columns containing 0: {}'.format(percent_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because we had exactly 60 items in each category this creates a list\n",
    "# with 60 items of each key.\n",
    "def create_labels(dictionary):\n",
    "    x = dictionary.keys()\n",
    "    new_list = []\n",
    "    for c in x: \n",
    "        s = [c] * len(dictionary[c])\n",
    "        new_list += s\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = create_labels(edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1080"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 13205)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aac</th>\n",
       "      <th>aaptiv</th>\n",
       "      <th>aarp</th>\n",
       "      <th>aask</th>\n",
       "      <th>ab</th>\n",
       "      <th>abajo</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcmous</th>\n",
       "      <th>...</th>\n",
       "      <th>zoomterrain</th>\n",
       "      <th>zoomwithushav</th>\n",
       "      <th>zoosk</th>\n",
       "      <th>zte</th>\n",
       "      <th>zulili</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zulufor</th>\n",
       "      <th>zulupermiss</th>\n",
       "      <th>zumba</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOOLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOOLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOOLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOOLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TOOLS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aac  aaptiv  aarp  aask   ab  abajo  abandon  abc  abcmous   ...    \\\n",
       "1075  0.0  0.0     0.0   0.0   0.0  0.0    0.0      0.0  0.0      0.0   ...     \n",
       "1076  0.0  0.0     0.0   0.0   0.0  0.0    0.0      0.0  0.0      0.0   ...     \n",
       "1077  0.0  0.0     0.0   0.0   0.0  0.0    0.0      0.0  0.0      0.0   ...     \n",
       "1078  0.0  0.0     0.0   0.0   0.0  0.0    0.0      0.0  0.0      0.0   ...     \n",
       "1079  0.0  0.0     0.0   0.0   0.0  0.0    0.0      0.0  0.0      0.0   ...     \n",
       "\n",
       "      zoomterrain  zoomwithushav  zoosk  zte  zulili  zulu  zulufor  \\\n",
       "1075          0.0            0.0    0.0  0.0     0.0   0.0      0.0   \n",
       "1076          0.0            0.0    0.0  0.0     0.0   0.0      0.0   \n",
       "1077          0.0            0.0    0.0  0.0     0.0   0.0      0.0   \n",
       "1078          0.0            0.0    0.0  0.0     0.0   0.0      0.0   \n",
       "1079          0.0            0.0    0.0  0.0     0.0   0.0      0.0   \n",
       "\n",
       "      zulupermiss  zumba  labels  \n",
       "1075          0.0    0.0   TOOLS  \n",
       "1076          0.0    0.0   TOOLS  \n",
       "1077          0.0    0.0   TOOLS  \n",
       "1078          0.0    0.0   TOOLS  \n",
       "1079          0.0    0.0   TOOLS  \n",
       "\n",
       "[5 rows x 13206 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aac</th>\n",
       "      <th>aaptiv</th>\n",
       "      <th>aarp</th>\n",
       "      <th>aask</th>\n",
       "      <th>ab</th>\n",
       "      <th>abajo</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcmous</th>\n",
       "      <th>...</th>\n",
       "      <th>zoompres</th>\n",
       "      <th>zoomterrain</th>\n",
       "      <th>zoomwithushav</th>\n",
       "      <th>zoosk</th>\n",
       "      <th>zte</th>\n",
       "      <th>zulili</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zulufor</th>\n",
       "      <th>zulupermiss</th>\n",
       "      <th>zumba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "      <td>1080.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.003569</td>\n",
       "      <td>0.005640</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.018597</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.004748</td>\n",
       "      <td>0.013862</td>\n",
       "      <td>0.022827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.023415</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.007396</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.002537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.035569</td>\n",
       "      <td>0.066420</td>\n",
       "      <td>0.185352</td>\n",
       "      <td>0.073265</td>\n",
       "      <td>0.066988</td>\n",
       "      <td>0.349607</td>\n",
       "      <td>0.018718</td>\n",
       "      <td>0.156044</td>\n",
       "      <td>0.387101</td>\n",
       "      <td>0.730989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116346</td>\n",
       "      <td>0.060580</td>\n",
       "      <td>0.116346</td>\n",
       "      <td>0.769504</td>\n",
       "      <td>0.039817</td>\n",
       "      <td>0.243071</td>\n",
       "      <td>0.071782</td>\n",
       "      <td>0.041430</td>\n",
       "      <td>0.069259</td>\n",
       "      <td>0.083370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 13205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                aa          aac       aaptiv         aarp         aask  \\\n",
       "count  1080.000000  1080.000000  1080.000000  1080.000000  1080.000000   \n",
       "mean      0.000033     0.000234     0.000172     0.000068     0.000062   \n",
       "std       0.001082     0.003569     0.005640     0.002229     0.002038   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.035569     0.066420     0.185352     0.073265     0.066988   \n",
       "\n",
       "                ab        abajo      abandon          abc      abcmous  \\\n",
       "count  1080.000000  1080.000000  1080.000000  1080.000000  1080.000000   \n",
       "mean      0.001763     0.000017     0.000144     0.001015     0.000834   \n",
       "std       0.018597     0.000570     0.004748     0.013862     0.022827   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.349607     0.018718     0.156044     0.387101     0.730989   \n",
       "\n",
       "          ...          zoompres  zoomterrain  zoomwithushav        zoosk  \\\n",
       "count     ...       1080.000000  1080.000000    1080.000000  1080.000000   \n",
       "mean      ...          0.000108     0.000056       0.000108     0.000713   \n",
       "std       ...          0.003540     0.001843       0.003540     0.023415   \n",
       "min       ...          0.000000     0.000000       0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000       0.000000     0.000000   \n",
       "50%       ...          0.000000     0.000000       0.000000     0.000000   \n",
       "75%       ...          0.000000     0.000000       0.000000     0.000000   \n",
       "max       ...          0.116346     0.060580       0.116346     0.769504   \n",
       "\n",
       "               zte       zulili         zulu      zulufor  zulupermiss  \\\n",
       "count  1080.000000  1080.000000  1080.000000  1080.000000  1080.000000   \n",
       "mean      0.000037     0.000225     0.000169     0.000038     0.000064   \n",
       "std       0.001212     0.007396     0.003225     0.001261     0.002107   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.039817     0.243071     0.071782     0.041430     0.069259   \n",
       "\n",
       "             zumba  \n",
       "count  1080.000000  \n",
       "mean      0.000077  \n",
       "std       0.002537  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       0.083370  \n",
       "\n",
       "[8 rows x 13205 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_desc = \"\"\"Find your next commercial real estate deal on the go! Leverage the power of LoopNet anytime, anywhere to find your perfect investment property or lease space right from your Android device. Whether in the office or on the road, the LoopNet app keeps you productive, informed, and ahead of the competition with these features:\n",
    "\n",
    "• Advanced Search Filters: Find the properties that meet your exact needs using specific search criteria and filtering options.\n",
    "• Comprehensive Property Details: View listing details including property data, photos, videos, financials, map location, satellite images, and street view. See something you like? Contact the broker right from your phone!\n",
    "• Map or List Based Search: Customize your search experience. Display and adjust your search results on a map, a list, or both.\n",
    "• Saved Searches & Notifications: Save searches that matter so you can access them quickly and monitor your market day-to-day. We’ll also keep you notified about new listings that match your saved search criteria.\n",
    "• Watch List & Notifications: Monitor listings of interest by adding them to your Watch List. We’ll notify you as soon as there are any changes or updates to the listings.\n",
    "• Multiple Device Capability: Access your saved searches and watched listings from any device or on the web through your LoopNet account.\n",
    "\n",
    "LoopNet is the industry leader with more traffic, listings, and geographic coverage than any other commercial real estate marketplace. Use the LoopNet app to find your next investment property or space to rent, whether office space, multifamily apartment buildings, retail, restaurant, medical, industrial, or land in all major markets in the United States and Canada including Los Angeles, New York, Chicago, San Francisco, Dallas, Houston, and Miami. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trial = text_cleaner(new_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vect = tfidf.transform([x_trial])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'find next commerci real estat deal go leverag power loopnet anytim anywher find perfect invest prope'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trial[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffff = pd.DataFrame(x_vect.toarray(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC CURVE FOR MODELS AND OTHERS SHOWING PREFORMANCE, <- CANT DO... \n",
    "# TEXT RELATED VIZUALISATIONS LIKE WORD CLOUD, LATENT SEMANTIC ANALYSIS\n",
    "# FEATURE IMPORTANCE ON RF, NB\n",
    "# CREATE VIZ OF ENSEMBLE MODELS\n",
    "# TYING SPECIFIC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test-Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPOT for automated model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'sklearn.naive_bayes.MultinomialNB': {\n",
    "        'alpha': [1e-3, 1e-2, 1e-1, 1., 10., 100.],\n",
    "        'fit_prior': [True, False]\n",
    "    },\n",
    "    'sklearn.svm.LinearSVC' : {\n",
    "        'C' : [1, 5, 10, 15, 20, 25],\n",
    "        'dual' : [True, False],\n",
    "        'loss' : [\"squared_hinge\", \"hinge\" ],\n",
    "        'penalty' : ['l1', 'l2']\n",
    "    },\n",
    "    'sklearn.neighbors.KNeighborsClassifier' : {\n",
    "    },\n",
    "    'sklearn.ensemble.RandomForestClassifier' : {\n",
    "        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Changed generation and population parameters to get better results\n",
    "tpot = TPOTClassifier(generations=5, cv = 3 ,population_size=20,\\\n",
    "                      max_eval_time_mins=10, verbosity=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.export('class4-pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.8009259259259259 First pipeline trial\n",
    "# 0.8055555555555556 Second pipeline trial\n",
    "# 0.7685185185185185 Third Pipeline trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = LinearSVC(C=10.0, dual=False, loss=\"squared_hinge\", penalty=\"l2\", tol=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last.predict(dffff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc1 = LinearSVC(C=25.0, dual=False, loss=\"squared_hinge\", penalty=\"l2\", tol=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc2 = LinearSVC(C=1.0, dual=True, loss=\"hinge\", penalty=\"l2\", tol=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(learning_rate=0.01, max_depth=6, max_features=0.2, min_samples_leaf=3, min_samples_split=15, n_estimators=100, subsample=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svc1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-93de21300608>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = VotingClassifier(estimators=[('svc1', svc1), \n\u001b[0m\u001b[1;32m      2\u001b[0m                                      \u001b[0;34m(\u001b[0m\u001b[0;34m'svc2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                      \u001b[0;34m(\u001b[0m\u001b[0;34m'gb_clf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgb_clf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     \u001b[0;34m(\u001b[0m\u001b[0;34m'nb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_classifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                     \u001b[0;34m(\u001b[0m\u001b[0;34m'knn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'svc1' is not defined"
     ]
    }
   ],
   "source": [
    "model = VotingClassifier(estimators=[('svc1', svc1), \n",
    "                                     ('svc2', svc2),\n",
    "                                     ('gb_clf', gb_clf),\n",
    "                                    ('nb', nb_classifier),\n",
    "                                    ('knn', knn),\n",
    "                                    ('rf', rf_classifier)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 with: svc1, svc2, last, gb_clf, nb, knn, rf\n",
    "# model2 with: svc1, svc2, gb_clf, nb, knn, rf\n",
    "# last -> SVC model \n",
    "#         LinearSVC(C=10.0, dual=False, loss=\"squared_hinge\", penalty=\"l2\", tol=0.1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# model1 => 0.8101851851851852 <- voting\n",
    "# model2 => 0.8148148148148148 <-voting\n",
    "# last => 0.8194444444444444 <-svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Store Models:\n",
    "# joblib.dump(model, 'model2')\n",
    "\n",
    "\n",
    "# To load model\n",
    "# model1 = joblib.load('model1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive-Bayes Multinomial Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "Training Accuracy: 0.9225 \t\t Testing Accuracy: 0.7454\n"
     ]
    }
   ],
   "source": [
    "nb_classifier.fit(X_train, y_train)\n",
    "nb_train_preds = nb_classifier.predict(X_train)\n",
    "nb_test_preds = nb_classifier.predict(X_test)\n",
    "\n",
    "nb_train_score = accuracy_score(y_train, nb_train_preds)\n",
    "nb_test_score = accuracy_score(y_test, nb_test_preds)\n",
    "\n",
    "print(\"Multinomial Naive Bayes\")\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(nb_train_score, nb_test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Training Accuracy: 1.0 \t\t Testing Accuracy: 0.7454\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "rf_train_preds = rf_classifier.predict(X_train)\n",
    "rf_test_preds = rf_classifier.predict(X_test)\n",
    "\n",
    "rf_train_score = accuracy_score(y_train, rf_train_preds)\n",
    "rf_test_score = accuracy_score(y_test, rf_test_preds)\n",
    "\n",
    "print('Random Forest')\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(rf_train_score, rf_test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "565"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = pca.fit_transform(X_train)\n",
    "new_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c6733b708942dc9bae0e411812eeff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=120, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "A pipeline has not yet been optimized. Please call fit() first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-7aae26870268>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtpot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tpot/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[1;32m    691\u001b[0m                     \u001b[0;31m# raise the exception if it's our last attempt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattempts\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tpot/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[1;32m    682\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_top_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_summary_of_best_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m                     \u001b[0;31m# Delete the temporary cache before exiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tpot/base.py\u001b[0m in \u001b[0;36m_update_top_pipeline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# If user passes CTRL+C in initial generation, self._pareto_front (halloffame) shoule be not updated yet.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# need raise RuntimeError because no pipeline has been optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'A pipeline has not yet been optimized. Please call fit() first.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_summary_of_best_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: A pipeline has not yet been optimized. Please call fit() first."
     ]
    }
   ],
   "source": [
    "tpot.fit(new_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.export('pca2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_pipeline = ExtraTreesClassifier(bootstrap=False, criterion=\"entropy\", max_features=0.5, min_samples_leaf=3, min_samples_split=7, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_pipeline.fit(new_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_pipeline.score(new_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.1,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last.fit(new_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8194444444444444"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last.score(new_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    #Add Normalization Option\n",
    "    '''prints pretty confusion metric with normalization option '''\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = last.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate = edu.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plot_confusion_matrix(cm, cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
